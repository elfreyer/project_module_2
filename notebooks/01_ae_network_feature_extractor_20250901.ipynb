{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f22ecb",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset\n",
    "\n",
    "- CIFAR-10 is a well-known benchmark dataset in computer vision.  \n",
    "- It contains 60,000 color images, each of size 32×32 pixels.  \n",
    "- There are 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.  \n",
    "- The dataset is split into:\n",
    "  - 50,000 training images\n",
    "  - 10,000 test images\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning Problem\n",
    "\n",
    "- **Type**: Supervised image classification  \n",
    "- **Task**: Learn to map image pixels to one of the 10 class labels.  \n",
    "- **Goal**: Train a model that correctly predicts the class of unseen test images.  \n",
    "- **Challenge**:  \n",
    "  - Low resolution makes feature extraction harder.  \n",
    "  - Some classes are visually similar (e.g., cat vs. dog, truck vs. automobile).  \n",
    "- **Use case for feature extractors**: Models can be trained to extract meaningful features from the images, which can then be used for classification or transferred to other tasks.\n",
    "\n",
    "## Pretrained Models\n",
    "\n",
    "- In TensorFlow (via `tf.keras.applications`), pretrained models are trained on **ImageNet** (1.2M images, 1000 classes).  \n",
    "- Popular choices include **MobileNetV2**, **EfficientNet**, **ResNet50**, and **InceptionV3**.  \n",
    "- These models expect **larger input sizes** (usually 224×224 pixels or higher).  \n",
    "  - To use them with CIFAR-10 (32×32), images must be **resized** to match the model’s expected input.  \n",
    "- Each model comes with a dedicated `preprocess_input` function that prepares images (scaling and normalization) consistently with how the model was trained.  \n",
    "- When used as **feature extractors**, we remove the final classification layer and keep the intermediate representation (embedding).  \n",
    "  - These embeddings capture **general visual patterns** (edges, textures, object parts) learned from ImageNet.  \n",
    "  - They can then be used to train a **new classifier** on CIFAR-10, or compared with **classical models** like Logistic Regression, SVM, kNN, or Random Forest.  \n",
    "\n",
    "### Why use pretrained models?\n",
    "- **Faster convergence**: We start from general-purpose vision features instead of random weights.  \n",
    "- **Better accuracy**: Even though CIFAR-10 is small, ImageNet-pretrained features transfer well.  \n",
    "- **Flexibility**: Embeddings can be reused for other datasets or tasks beyond CIFAR-10.  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18c872",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ddb021",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503cf555",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe81e1c",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b608ded",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ffe22",
   "metadata": {},
   "source": [
    "# Results and interpretations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
